{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DESCRIPTION:\n",
    "    This example shows how to use OpenAI with your data. In this case we are using the Moby Dick book online. \n",
    "    We will create embeddings from urls and save it in Azure Data Explorer\n",
    "    Then we will query Azure Data Explorer and get an answer using OpenAI by using the Retrieval Augmented Generation method.\n",
    "### REQUIREMENTS:\n",
    "    Create an .env file with your OpenAI API key and save it in the root directory of this project.\n",
    "\n",
    "### Langchain library\n",
    "Load your venv and run the following command:\n",
    "pip install langchain[all]\n",
    "\n",
    "### PREPARATION\n",
    "* An ADX (Azure Data Explorer or Kusto) cluster  \n",
    "* In ADX, create a Database named \"openai\"  \n",
    "    <img src=\"images/1.png\" alt=\"Create Kusto cluster\" /> \n",
    "* Create a table called wikipedia by ingesting data from \"./data/wikipedia/vector_database_wikipedia_articles_embedded_1000.csv\"   \n",
    "    <img src=\"images/2.png\" alt=\"Create Kusto cluster\" /> \n",
    "* Create an AAD app registration for Authentication - see below   \n",
    "    [Create an Azure Active Directory application registration in Azure Data Explorer](https://learn.microsoft.com/en-us/azure/data-explorer/provision-azure-ad-app)\n",
    "\n",
    "* You need to add ADX function as follows:   \n",
    "     Run this on ADX Explorer UI  \n",
    "     \n",
    "```\n",
    "//create the cosine similarity function for embeddings\n",
    ".create-or-alter function with (folder = \"Packages\\\\Series\", docstring = \"Calculate the Cosine similarity of 2 numerical arrays\")\n",
    "series_cosine_similarity_fl(vec1:dynamic, vec2:dynamic, vec1_size:real=double(null), vec2_size:real=double(null))\n",
    "{\n",
    "    let dp = series_dot_product(vec1, vec2);\n",
    "    let v1l = iff(isnull(vec1_size), sqrt(series_dot_product(vec1, vec1)), vec1_size);\n",
    "    let v2l = iff(isnull(vec2_size), sqrt(series_dot_product(vec2, vec2)), vec2_size);\n",
    "    dp/(v1l*v2l)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "from openai.embeddings_utils import get_embedding\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import tiktoken\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import utils\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT!! Embeddings Creation Section - Run this only once\n",
    "You only need to run this once to create the embeddings and save them to Azure Data Explorer.   \n",
    "Then you can use the already created database and table in Azure Data explorer for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1804"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embeddings from urls and save it to a FAISS index.\n",
    "openai = utils.init_OpenAI()\n",
    "embeddings = utils.init_embeddings()\n",
    "\n",
    "# you can add as many urls as you want, but for this example we will only use one\n",
    "# \"moby dick\" the book is available online at the URL below\n",
    "urls = [\"https://www.gutenberg.org/files/2701/2701-0.txt\"]\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "documents = loader.load()\n",
    "\n",
    "#we use chunk size of 1000 and 10% overlap to try not to cut sentences in the middle\n",
    "#this regex separates by placing the sentence period when cutting a chunk at the end of that chunk\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"])\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the tenacity library to create delays and retries when calling openAI to avoid hitting throtlling limits\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def calc_embeddings(text, deployment):\n",
    "    # replace newlines, which can negatively affect performance.\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return get_embedding(text, engine=deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.gutenberg.org/files/2701/2701-0.txt</td>\n",
       "      <td>The Project Gutenberg eBook of Moby-Dick; or T...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.gutenberg.org/files/2701/2701-0.txt</td>\n",
       "      <td>CONTENTS\\n\\nETYMOLOGY.\\n\\nEXTRACTS (Supplied b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.gutenberg.org/files/2701/2701-0.txt</td>\n",
       "      <td>CHAPTER 33. The Specksnyder.\\n\\nCHAPTER 34. Th...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.gutenberg.org/files/2701/2701-0.txt</td>\n",
       "      <td>CHAPTER 58. Brit.\\n\\nCHAPTER 59. Squid.\\n\\nCHA...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.gutenberg.org/files/2701/2701-0.txt</td>\n",
       "      <td>CHAPTER 85. The Fountain.\\n\\nCHAPTER 86. The T...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     document_name  \\\n",
       "0  https://www.gutenberg.org/files/2701/2701-0.txt   \n",
       "1  https://www.gutenberg.org/files/2701/2701-0.txt   \n",
       "2  https://www.gutenberg.org/files/2701/2701-0.txt   \n",
       "3  https://www.gutenberg.org/files/2701/2701-0.txt   \n",
       "4  https://www.gutenberg.org/files/2701/2701-0.txt   \n",
       "\n",
       "                                             content embedding  \n",
       "0  The Project Gutenberg eBook of Moby-Dick; or T...            \n",
       "1  CONTENTS\\n\\nETYMOLOGY.\\n\\nEXTRACTS (Supplied b...            \n",
       "2  CHAPTER 33. The Specksnyder.\\n\\nCHAPTER 34. Th...            \n",
       "3  CHAPTER 58. Brit.\\n\\nCHAPTER 59. Squid.\\n\\nCHA...            \n",
       "4  CHAPTER 85. The Fountain.\\n\\nCHAPTER 86. The T...            "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save all the chunks into a pandas dataframe\n",
    "df = pd.DataFrame(columns=['document_name', 'content', 'embedding'])\n",
    "for ch in chunks:\n",
    "    dict = {'document_name': ch.metadata['source'],'content': ch.page_content, 'embedding': \"\"}\n",
    "    temp_df = pd.DataFrame(dict, index=[0])\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      document_name  \\\n",
      "0   https://www.gutenberg.org/files/2701/2701-0.txt   \n",
      "1   https://www.gutenberg.org/files/2701/2701-0.txt   \n",
      "2   https://www.gutenberg.org/files/2701/2701-0.txt   \n",
      "3   https://www.gutenberg.org/files/2701/2701-0.txt   \n",
      "4   https://www.gutenberg.org/files/2701/2701-0.txt   \n",
      "..                                              ...   \n",
      "95  https://www.gutenberg.org/files/2701/2701-0.txt   \n",
      "96  https://www.gutenberg.org/files/2701/2701-0.txt   \n",
      "97  https://www.gutenberg.org/files/2701/2701-0.txt   \n",
      "98  https://www.gutenberg.org/files/2701/2701-0.txt   \n",
      "99  https://www.gutenberg.org/files/2701/2701-0.txt   \n",
      "\n",
      "                                              content  \\\n",
      "0   The Project Gutenberg eBook of Moby-Dick; or T...   \n",
      "1   CONTENTS\\n\\nETYMOLOGY.\\n\\nEXTRACTS (Supplied b...   \n",
      "2   CHAPTER 33. The Specksnyder.\\n\\nCHAPTER 34. Th...   \n",
      "3   CHAPTER 58. Brit.\\n\\nCHAPTER 59. Squid.\\n\\nCHA...   \n",
      "4   CHAPTER 85. The Fountain.\\n\\nCHAPTER 86. The T...   \n",
      "..                                                ...   \n",
      "95  Whether that mattress was stuffed with corn-co...   \n",
      "96  Lord save me, thinks I, that must be the harpo...   \n",
      "97  he is, just from the surgeon. But at that mome...   \n",
      "98  It’s only his outside; a man can be honest in ...   \n",
      "99  down into the bag. He now took off his hat—a n...   \n",
      "\n",
      "                                            embedding  \n",
      "0   [-0.018551234155893326, -0.029452474787831306,...  \n",
      "1   [0.00291403173469007, -0.0002718802134040743, ...  \n",
      "2   [0.0037181228399276733, -0.008589204400777817,...  \n",
      "3   [-0.001436485443264246, -0.010900440625846386,...  \n",
      "4   [0.0026240660808980465, -0.0018162619089707732...  \n",
      "..                                                ...  \n",
      "95  [0.010987200774252415, -0.008510278537869453, ...  \n",
      "96  [-0.0020237795542925596, -0.004040727857500315...  \n",
      "97  [-0.01145096030086279, -0.0058190664276480675,...  \n",
      "98  [-0.0012879909481853247, -0.002086040331050753...  \n",
      "99  [-0.02059198170900345, -0.014046011492609978, ...  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df[\"embedding\"] = df.content.apply(lambda x: calc_embeddings(x, utils.OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME))\n",
    "print(df.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/adx/adx_embeddings.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to Azure Data Explorer section\n",
    "* You need to do this only once.   \n",
    "* We have read the document in the URL\n",
    "* Splitted it into chunks\n",
    "* Created the embeddings\n",
    "* Saved the text chunks and correspoding embeddings to a CSV\n",
    "\n",
    "Now we will ingest the CSV (must be less than 1 GB)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval section\n",
    "You can use the already created database and table in Azure Data explorer for retrieval by running the cells here below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = utils.init_llm()\n",
    "embeddings = utils.init_embeddings()\n",
    "vectorStore = FAISS.load_local(\"./dbs/urls/faiss_index\", embeddings)\n",
    "retriever = vectorStore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa({\"query\": \"Why does the coffin prepared for Queequeg become Ishmael's life buoy once the Pequod sinks?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa({\"query\": \"Why does Ahab pursue Moby Dick so single-mindedly?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa({\"query\": \"Why does the novel's narrator begin his story with 'Call me Ishmael'?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
