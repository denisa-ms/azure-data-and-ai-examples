{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DESCRIPTION:\n",
    "    This example shows how to summarize Youtube video transcripts using Azure OpenAI and Langchain chains.\n",
    "\n",
    "### REQUIREMENTS:\n",
    "    Create an .env file with your OpenAI API key and save it in the root directory of this project.\n",
    "\n",
    "### For more information about Langchain agent toolkits, see:\n",
    "  TBD - blog post here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "# https://www.youtube.com/watch?v=FaV0tIaWWEg\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=FaV0tIaWWEg\",\n",
    "    add_video_info=False\n",
    ")\n",
    "video_transcripts = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foreign have you built systems on top of Microsoft azure's data and analytics services are you wondering what Microsoft fabric means for your existing Investments and skills I recently spoke to someone who is uniquely well placed to talk about these things in fact he had so much to say about fabric though we split this recording into three parts if you want to hear the other two please make sure that you subscribed to this channel so with me today I have Tom peplow who is a principal at milliman and we also have engine's very own ad Freeman who is a senior data engineer now I'm really excited to be able to talk to Tom today about fabric because milliman have been Pioneers in the world of high performance cloud-based computation and analytics they've been Building Systems in this way since 2010 so they know a great deal about how to do this so Tom don't you already have everything you need does fabric bring anything to to the party for you yeah um we do have a lot right and we've built a lot over a long time uh but we that's one of the challenges I think that we have is you know our differentiated value in the market is Actuarial computations um we want to make it easy for actuaries to do um to do their job and that means that we need to give them a breadth of tools to do you know all the things that are important to actuaries and a big part of that is data analytics um they run models to project um how insurance companies are going to perform out into the future which generates huge amounts of data for them huge amounts of valuable Insight they can use to better plan for the future design better products and help keep people safe um and it's been pretty difficult really to kind of handle that much data um and give them tools to report on it well it's required us to to build and glue together lots of capabilities from Azure and we've evolved it you know when we started we used to do now we use um spark so that was a transition our analytics uses power bi embedded which is fantastic um and we embed ETL capabilities from data Factory too so they can self-serve um these things but um you know we've put together a lot of capabilities ourselves and we have to look after that and I think where Fabrics helpful um is it could be disruptive to our strategy of how we glue together all these things um I mean if If This Were A Thing 10 years ago we would have used it uh it's now a thing we have to decide if we're going to use it um so we're in the process of evaluating whether it solves the problems better than we've sold them um there's obviously other other players in the mix too there's other vendors who have similar Solutions but um we're very much uh looking at fabric as a mechanism for us to deliver more value to our customers without having to write as much code uh for the long run and I assume Tom it's uh it's weighing up the cost of kind of upskilling on a on kind of a new um Microsoft data platform versus the benefits that you might get from this kind of a new sassification and self-service um flavor of a Microsoft data platform I suppose when you've done uh kind of platform migrations in the past how how um how easy has it been for the uh the actuaries to actually get get used to a new platform um so one of the interesting things we've tried to do is to try and shield the customer for as much change as possible um like for example data Factory if you want data Factory to V2 was kind of a transparent thing I didn't notice uh we could run We've ran both side by side so that we could evaluate when V2 is performing as we like at the scale which we pushed it um so we have you know engineering ways that we can we can do that safely where it becomes difficult is when the user experience is the thing that changes right because they've got to click the buttons and the screens do the things they want to do uh so in every time you've when we move from Hadoop to um it's your data Factory for example um we use mapping data flows instead of pig um you know that was a very visible change to the users because they went from writing Pig in it in Hadoop to building um uh data flow code in in in ADF uh so we you know they could choose when they wanted to do it and we kind of left the both capabilities exist in our platform still today and you know you can choose which you use um over time it was evident that the newer technology that we brought to bear was was worth using and customers just use more of it so um we try and provide options to keep people feeling comfortable that they can do their job today whilst providing them better options to their job in the future yeah and I think one of the benefits with with Microsoft fabric especially from a end user perspective is it is kind of the foundational blocks are built on the the power bi service and the power bi UI so there is there should be kind of a level of familiarity that the existing power bi users will have with that that being said it's still new new types of artifacts laid out in a slightly different way there's always going to be some sort of a kind of upskilling exercise I think yeah they've done quite a quite a nice job of trying to keep it similar and the user experience across the new things that have come in notebooks the way it integrates the way it kind of plays with the other components they've thought about the integration which I think is actually really important because it's that handoff between needing to do data transformation to looking at information you don't want to have to jump through lots of different Technologies right we tried to make that easy for our users ourselves it was very easy to you know do some Transformations look at the results but you know having that really stuck together by the vendor is is critical because it just the things you need to do to be efficient and lower that in a loop development cycle time so you're going from doing your work to checking your work to automating your work um making that real tight is where you get value because people struggle to retain context you know we know as developers of our unit tests are slow it stresses us out right so we want that same experience for our customers we want them to be able to build models analyze the results from Models as tightly as possible which requires us to run on large computations that scale to generate huge amounts of data for them to look at and then just making that really fast and really seamless we're going to have to stick our data and calculations in a platform to make that happen because no one else has Rip but um what we want to do is when they're in that platform that everything is really seamlessly integrated so they're doing the job as quickly and as easily as they possibly can so do you think that fabric is mainly going to just reduce your engineering and operational costs because it does more of the things that you used to have to do yourself or do you think there's actually any fundamentally enabling features in it that you couldn't in principle build for yourself yeah one Lake's huge and one of the biggest challenges we have is how do we Federate our information with our customers both directions you know that what we get given to us is um every insurance policy holder they've got across all the blocks of business they've ever issued every asset they've invested in um with every asset provider they've got um economic scenario data Bloomberg feeds all these types of data come from all these types of places from all these different types of vendors and it's hard to do that you know what it's like when you do these big data integration projects and we've got customers there's hundreds of separate feeds of information coming through to us um we then obviously take that and run actually our models produce really valuable insight to the business it's a big old data set we have to heavily aggregate it before we can give it back to them so being able to have this Federated environment where all of our data sits together and can be queried together with super low latency I mean the the what we could be able to do with a technology like one like is is really compelling because the way I think of this is like Cloud vendors can do this but providers you sit on top of the cow couldn't so my bits and bytes are stored on the physical hard disk in azure um which and adds bits and bytes are also stored kind of in the same place where they're all muddled up so when I query my data it's not really any different to me querying Ed's data it's just I don't have permission to get to Ed's data uh that means that they have the optimal the opportunity to optimize queries in ways that others couldn't because they own the security right close to the data and do you think the um the standardization on this Open Table format and in Delta lake is that is that something you or even your kind of your actuaries care about or um will that actually enable you to do anything different with kind of cross-cloud or um using existing say databricks workspaces to read and write that to those tables do you see any benefit in that I think the openness is key um like I described earlier people's transitions are going to be incremental um it remains to be seen the Fabric's going to win or be adopted right so being able to make a bet that will work if technology changes on us is huge so be not being locked into a particular technology because of Open Standards is very important I also think that you know the internet is probably the most successful information system that exists and it has no in it has no challenges sharing information right you can click one link and land on a different page and that was the beauty of the idea right is it was completely standards based nobody owned that technology it's owned by the community and you can you can improve it together so if we start thinking about the challenges inside of organizations federating data across departments is hard federating data across businesses is hard there's technology and standards that have done it at super big scale um so I really think that standards are a big enabler for this to start to happen much more smoothly within organizations so one of the things that seems to change with fabric compared to synapse for example and you've touched on this a little bit is it seems to be much more end user focused it feels like it's sort of more of an office suite thing than a kind of developer oriented tool um are there do you see both pros and cons of that shift more to that end um I do it's interesting because um you know my job has me out on the road seeing our customers and one of the things I've been doing is asking the customers what they think of this now it's public right and we were able to bring some of our customers in on the private preview when it was known as Trident too so we've been able to have some some dialogue with them I think there's a huge amount of excitement on the business side um I think there's I can't find this presentation I wish I could find it but I saw Amy Hood talk once about the finance transformation inside of Microsoft's accounting department and that's what we do we do Actuarial Transformations very similar to what Amy would have had to have done with Microsoft's Finance team and a key thing that she said was that the accountants could do a lot themselves without needing to rely on I.T which freed it up to do a huge amount of other valuable things for the business not having to worry about how to build a balance sheet for an accountant actuaries are like accountants on steroids the types of things they want to do with data is not is not um easily explained to people in it right so they're very excited because it's like I get more data I get to do more things with that data I can do my job more easily so that's good and that was a big enabler for Microsoft's accounting transformation um on the other side though you've got you've got fear you know everybody remembers access databases right so I've literally heard from a customer it's like this is just going to be like access all over again right um and you know the other thing is around the thin UPS how much are these people going to spend doing this type of analytics you know are they going to be are they going to be strict at making sure there's a good Roi and all the stuff they do because what you can do with this is you know you ultimately can spend a lot of money um so I think there's apprehension in um the I.T side there's also apprehension because they're in a similar position to I'm in so we have an existing platform that works that we need to decide what to do with do we continue to invest or do we look to disrupt it um and I think my dilemma is the same as everyone else's dilemma because Lots it's not like it was like Cloud 101 when we're back in 2010 when no one was in the cloud and we're bringing them there um now it's like we're there and we've got platforms they like and work and now this is a particularly disruptive change to that because Microsoft have glued all the bits together for you so you don't have to glue them together yourself but then what do you do what do you do with all the glue bill um so I hear both sides businesses kind of like it and the uh me and uh the I.T side are kind of trying to figure out what to do with it I was as surprised from from that perspective from it uh kind of in a in a tug of war with with the actual users how how kind of difficult is it in a large Enterprise like like yours to put in those guard rails to make sure that the things don't turn into a mess and and kind of the actuaries don't start churning loads of money and they don't start creating loads of artifacts that um they end up abandoning is it's it's a non-trivial exercise right to try and put those guardrails in place keeping kind of I.T and the government governance team happy um with with how people are using the platform yeah so we we think about we we are trying to bring uh like a software engineering approach to Actuarial science right and if you think about what software Engineers do is they have a development environment where they build and test their software and then when they're done they put it into a production environment so that simple separation of ge's between I'm doing my work and I'm building the things too I'm running with things and looking at the numbers does introduce some rigor because you can put devops and finops around the process of being in production so I built a model I want to put it in production you can ask them the question how much does it cost to run do you have reports around it what's the impact of the change you just made and you can control the changes from one place to the other and then you increase and then you don't frustrate them because you have a robust um CI CD process for promoting changes from development into production so what you get is a not frustrated user they're not like there's not a whole load of governance stopping them getting their job done but you don't get a frustrated I.T uh Team because you're not putting um not very good stuff into production it's very expensive to run on the other side though sometimes you've got to answer questions quickly because your boss comes to you and says what's the impact of this thing that's just happened yesterday right we do some really clever stuff with machine learning to train model so they can you know evaluate market conditions now based on not having to run these big heavy models that's really powerful but the other thing is like sometimes you just got runner models sometimes it's got to change some assumptions sometimes I've got to go spend some money uh when it's aligned to Value if the CFO over large insurance company is asking you to do something quick they're not really going to care how much it costs if they get the answer on time so and then it's just creating the accountability back to track all that through right so being robust and mature about it is not a technology problem it's a process problem and I suppose fabric does seem to have kind of taken that on board whereas kind of power bi in the early days didn't really it didn't really think about kind of the CI CD the devops and kind of the fin Ops behind power bi so much that all came much more recently but fabric seems to be from the outset bringing in the principles like Version Control we're going to get integration in at the in the kind of the fabric portal layer um and the soon to come will be a a sway of apis to to drive all of these things so I suppose from your perspective you want that rigor that that that surely is um a very good thing definitely using gets huge uh two reasons one um they've had to do a lot of work to decompose the power bi artifacts so they can be version controlled it's really helpful second is it standards based is git so you can integrate with it easily which is huge so then we've got mechanisms for putting our modeling technology alongside technology that we don't own the IPL so um they are listening this is one of the things that with fabric it they've done they've taken some time to get there because it was a big investment but all the things that the community were asking for in fabric you know better controls better governance better automation um more openness Version Control all these things just out of the box there are lots of things that we had to build though we we do Version Control power bi artifacts in our platform because it's important for us when the regulator comes to us and asks why are these numbers these numbers we have to be able to answer that question and at the time Microsoft didn't give us a mechanism for version controlling power bi so we essentially version controlled it as a black box which isn't a particularly elegant solution because we can't show you what changed so things are getting better um and they're obvious places that we can reinvest in modernizing so that they get a better experience around before we go in the next part Tom will talk about the relationship between Microsoft Fabric and AI if you enjoyed this first part please click the like button and if you want to make sure that you catch the next part please subscribe to this channel [Music]\n"
     ]
    }
   ],
   "source": [
    "# Access the content and metadata of each document - let's ee how it looks like\n",
    "for document in video_transcripts:\n",
    "    content = document.page_content\n",
    "    metadata = document.metadata\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Microsoft was founded in 1975 by Bill Gates and Paul Allen. Its current best-selling products are the Microsoft Windows operating system, Microsoft Office, Xbox, Bing, and Microsoft Azure. Microsoft Office has gone through various versions since its first release in 1989, with Word being a part of the suite. The first version of Word was released in 1983 and has gone through various updates and revisions over the years.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's use the Wikipedia tool and create a langchain agent that uses it\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "import utils\n",
    "\n",
    "llm = utils.init_llm()\n",
    "tools = load_tools([\"wikipedia\"], llm=llm)\n",
    "agent = initialize_agent(tools,\n",
    "                         llm,\n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         verbose=False)\n",
    "\n",
    "# let's use the agent to get information about Microsoft\n",
    "agent.run(\"Microsoft history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use a sequence of prompts to create a chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.memory import SimpleMemory\n",
    "\n",
    "# chain 1 - get background info Microsoft\n",
    "ch1 = agent\n",
    "\n",
    "# chain 2 - summarize the video transcript from youtube\n",
    "template = \"\"\"Create an article summarizing the text below for an article, be concise and use bullets to explain. Use no more than {article_length} words.\n",
    "\n",
    "Company information:\n",
    "{input}\n",
    "\n",
    "Video transcript:\n",
    "{video_transcript}\n",
    "\n",
    "Create an article:\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"input\", \"article_length\", \"video_transcript\"], template=template)\n",
    "ch2 = LLMChain(llm=llm, prompt=prompt_template) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input', 'agent_scratchpad']\n"
     ]
    }
   ],
   "source": [
    "# check the expected input variables \n",
    "print(ch1.agent.llm_chain.prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_chain = SequentialChain(\n",
    "                input_variables=[\"input\", \"video_transcript\"],\n",
    "                memory=SimpleMemory(memories={\"article_length\": \"500\"}),\n",
    "                chains=[ch1, ch2],\n",
    "                verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Microsoft CEO Satya Nadella kicked off the company's Build developer conference with a keynote address highlighting the importance of innovation and technology in driving economic growth and human development. Nadella discussed the company's history, tracing its roots back to the early days of computing and highlighting the role of AI in the current era. He also discussed Microsoft's latest initiatives, including the launch of Microsoft Fabric, a unified data analytics platform that combines compute and storage. Nadella also highlighted the company's efforts to promote AI safety, emphasizing the importance of building safety into the everyday toolchain. Finally, he showcased the potential of AI to transform people's lives, sharing a video about Jugalbandi, a chatbot that provides access to information about government schemes and services for people living in media-dark areas in India. Overall, Nadella's keynote emphasized the importance of innovation and technology in driving economic growth and human development, and highlighted Microsoft's role as a leader in the field.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_chain.run(input=\"The history of Microsoft\", video_transcript=video_transcripts[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
